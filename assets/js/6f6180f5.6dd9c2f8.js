"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[1309],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>h});var a=r(67294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},o=Object.keys(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var l=a.createContext({}),u=function(e){var t=a.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=u(r),m=n,h=c["".concat(l,".").concat(m)]||c[m]||d[m]||o;return r?a.createElement(h,i(i({ref:t},p),{},{components:r})):a.createElement(h,i({ref:t},p))}));function h(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=r.length,i=new Array(o);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:n,i[1]=s;for(var u=2;u<o;u++)i[u]=r[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,r)}m.displayName="MDXCreateElement"},70787:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>u});var a=r(87462),n=(r(67294),r(3905));const o={slug:"introduce-vector-search-to-your-favourite-database-with-superduperdb",title:"Introduce vector search to your favourite database with SuperDuperDB",authors:["blythed"],tags:["AI","vector-search"]},i=void 0,s={permalink:"/blog/introduce-vector-search-to-your-favourite-database-with-superduperdb",editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/blog/2023-09-09-vector-search.md",source:"@site/blog/2023-09-09-vector-search.md",title:"Introduce vector search to your favourite database with SuperDuperDB",description:"In 2023 vector-databases are hugely popular; they provide the opportunity for developers to connect LLMs, such as OpenAI\u2019s GPT models, with their data, as well as providing the key to deploying \u201csearch-by-meaning\u201d on troves of documents.",date:"2023-09-09T00:00:00.000Z",formattedDate:"September 9, 2023",tags:[{label:"AI",permalink:"/blog/tags/ai"},{label:"vector-search",permalink:"/blog/tags/vector-search"}],readingTime:4.79,hasTruncateMarker:!0,authors:[{name:"Duncan Blythe",title:"Creator of SuperDuperDB",url:"https://github.com/blythed",imageURL:"https://avatars.githubusercontent.com/u/15139331?v=4",key:"blythed"}],frontMatter:{slug:"introduce-vector-search-to-your-favourite-database-with-superduperdb",title:"Introduce vector search to your favourite database with SuperDuperDB",authors:["blythed"],tags:["AI","vector-search"]},prevItem:{title:"Building a Documentation Chatbot using FastAPI, React, MongoDB and SuperDuperDB",permalink:"/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb"},nextItem:{title:"Introducing SuperDuperDB: Bringing AI to your Datastore in Python",permalink:"/blog/bringing-ai-to-your-datastore-in-python"}},l={authorsImageUrls:[void 0]},u=[{value:"Enter SuperDuperDB",id:"enter-superduperdb",level:3},{value:"Minimal boilerplate to connect to SuperDuperDB",id:"minimal-boilerplate-to-connect-to-superduperdb",level:3},{value:"Set up vector-search with SuperDuperDB in one command",id:"set-up-vector-search-with-superduperdb-in-one-command",level:3},{value:"SuperDuperDB is licensed under Apache 2.0 and is a community effort!",id:"superduperdb-is-licensed-under-apache-20-and-is-a-community-effort",level:3}],p={toc:u},c="wrapper";function d(e){let{components:t,...r}=e;return(0,n.kt)(c,(0,a.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"In 2023 vector-databases are hugely popular; they provide the opportunity for developers to connect LLMs, such as OpenAI\u2019s GPT models, with their data, as well as providing the key to deploying \u201csearch-by-meaning\u201d on troves of documents."),(0,n.kt)("p",null,"However: a key unanswered question, for which there is no widely accepted answer, is:"),(0,n.kt)("p",null,"How do the vectors in my vector-database get there in the first place?"),(0,n.kt)("p",null,"Vectors (arrays of numbers used in vector-search) differ from the content of most databases, since they need to be calculated on the basis of other data."),(0,n.kt)("p",null,"Currently there are 2 approaches:"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"}," Possibility 1: models live together with the database to create vectors at insertion time ")),(0,n.kt)("p",null,"When data is inserted into a vector-database, the database may be configured to \u201ccalculate\u201d or \u201ccompute\u201d vectors on the basis of this data (generally text). This means that the database environment also has access to some compute and AI models, or access to APIs such as OpenAI, in order to obtain vectors."),(0,n.kt)("p",null,"Examples of this approach are:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Weaviate (support for a range of pre-defined models, some support for bringing own model)"),(0,n.kt)("li",{parentName:"ul"},"Chroma (support for OpenAI and sentence_transformers)")),(0,n.kt)("p",null,"Pros:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"The data and compute live together, so developers don\u2019t need to create an additional app in order to use the vector-database")),(0,n.kt)("p",null,"Cons:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Developers are limited by the models available in the vector-database and the compute resources on the vector-database server"),(0,n.kt)("li",{parentName:"ul"},"Primary data needs to be stored in the vector-database; classic-database + external vector-search isn\u2019t an expected pattern."),(0,n.kt)("li",{parentName:"ul"},"Training of models is generally not supported.")),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"}," Possibility 2: the vector-database requires developers to provide their own vectors with their own models ")),(0,n.kt)("p",null,"In this approach, developers are required to build an app which deploys model computations over data which is extracted from the datastore."),(0,n.kt)("p",null,"Examples of this approach are:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"LanceDB"),(0,n.kt)("li",{parentName:"ul"},"Milvus")),(0,n.kt)("p",null,"Pros:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"By developing a vector-computation app, the user can use the full flexibility of the open-source landscape for computing these vectors, and can architect compute resources independently from vector-database resources"),(0,n.kt)("li",{parentName:"ul"},"The vector-database \u201cspecializes\u201d in vector-search and storage of vectors, giving better performance guarantees as a result")),(0,n.kt)("p",null,"Cons:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Huge overhead of building one\u2019s own computation app."),(0,n.kt)("li",{parentName:"ul"},"All communication between app, vector-database and datastore (if using external datastore) must be managed by the developer")),(0,n.kt)("h3",{id:"enter-superduperdb"},"Enter SuperDuperDB"),(0,n.kt)("p",null,"SuperDuperDB is a middle path to scalability, flexiblity and ease-of-use in vector-search and far beyond."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB is an open-source Python environment which wraps databases and AI models with additional functionality to make them \u201cready\u201d to interface with one-another; developers are able to host their data in a \u201cclassical\u201d database, but use this database as a vector-database."),(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB allows users to integrate any model from the Python open source ecosystem (torch, sklearn, transformers, sentence_transformers as well as OpenAI\u2019s API), with their datastore. It uses a flexible scheme, allowing new frameworks and code-bases to be integrated without requiring the developer to add additional classes or functionality."),(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB can be co-located with the database in infrastructure, but at the same time has access to its own compute, which is scalable. This makes it vertically performant and at the same time, ready to scale horizontally to accommodate larger usage."),(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB enables training directly with the datastore: developers are only required to specify a database-query to initiate training on scalable compute."),(0,n.kt)("li",{parentName:"ul"},"Developers are not required to program tricky boilerplate code or architectures for computing vector outputs and storing these back in the database. This is all supported natively by SuperDuperDB."),(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB supports data of arbitrary type: with its flexible serialization model, SuperDuperDB can handle text, images, tensors, audio and beyond."),(0,n.kt)("li",{parentName:"ul"},"SuperDuperDB\u2019s scope goes far beyond vector-search; it supports models with arbitrary outputs: classification, generative AI, fore-casting and much more are all within scope and supported. This allows users to build interdependent models, where base models feed their outputs into downstream models; this enables transfer learning, and quality assurance via classification on generated outputs, to name but 2 key outcomes of SuperDuperDB\u2019s integration model.")),(0,n.kt)("h3",{id:"minimal-boilerplate-to-connect-to-superduperdb"},"Minimal boilerplate to connect to SuperDuperDB"),(0,n.kt)("p",null,"Connecting to MongoDB with SuperDuperDB is super easy. The connection may be used to insert documents, although insertion/ ingestion can also proceed via other sources/ client libraries."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import json\nimport pymongo\n\nfrom superduperdb import superduper\nfrom superduperdb.container.document import Document\nfrom superduperdb.db.mongodb.query import Collection\n\ndb = pymongo.MongoClient().documents\ndb = superduper(db)\n\ncollection = Collection('wikipedia')\n\nwith open('wikipedia.json') as f:\n    data = json.load(f)\n\ndb.execute(\n    collection.insert_many([Document(r) for r in data])\n)\n")),(0,n.kt)("h3",{id:"set-up-vector-search-with-superduperdb-in-one-command"},"Set up vector-search with SuperDuperDB in one command"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.container.vector_index import VectorIndex\nfrom superduperdb.container.listener import Listener\nfrom superduperdb.ext.numpy.array import array\nfrom superduperdb.ext.openai import OpenAIEmbedding\n\ndb.add(\n    VectorIndex(\n        identifier=f'wiki-index',\n        indexing_listener=Listener(\n            model=OpenAIEmbedding(model='text-embedding-ada-002'),\n            key='abstract',\n            select=collection.find(),\n            predict_kwargs={'max_chunk_size': 1000},\n        )\n    )\n)\n")),(0,n.kt)("p",null,"This approach is simple enough to allow models from a vast range of libraries and sources to be implemented: open/ closed source, self-built or library based and much more."),(0,n.kt)("p",null,"Now that the index has been created, queries may be dispatched in a new session to SuperDuperDB without reloading the model:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"cur = db.execute(\n    collection\n        .like({'title': 'articles about sport'}, n=10, vector_index=f'wiki-index')\n        .find({}, {'title': 1})\n)\n\nfor r in cur:\n    print(r)\n")),(0,n.kt)("p",null,"The great thing about using MongoDB or a similar battle tested database for vector-search, is that it can be easily combined with important filtering approaches. In this query, we restrict the results to a hard match involving the word \u201cAustralia\u201d:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"cur = db.execute(\n    collection\n        .like({'title': 'articles about sport'}, n=100, vector_index=f'wiki-index-{model.identifier}')\n        .find({'title': {'$regex': '.*Australia'}})\n)\n\nfor r in cur:\n    print(r['title'])\n")),(0,n.kt)("h3",{id:"superduperdb-is-licensed-under-apache-20-and-is-a-community-effort"},"SuperDuperDB is licensed under Apache 2.0 and is a community effort!"),(0,n.kt)("p",null,"We would like to encourage developers interested in the project to contribute in our discussion forums, issue boards and by making their own pull requests. We'll see you on\xa0GitHub!"))}d.isMDXComponent=!0}}]);