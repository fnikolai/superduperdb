"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[6581],{92322:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var s=o(85893),t=o(11151);const r={},a="Cluster usage",i={id:"use_cases/productionization/sandbox-example",title:"Cluster usage",description:'SuperDuperDB allows developers, on the one hand to experiment and setup models quickly in scripts and notebooks, and on the other hand deploy persistent services, which are intended to "always" be on. These persistent services are:',source:"@site/content/use_cases/productionization/sandbox-example.md",sourceDirName:"use_cases/productionization",slug:"/use_cases/productionization/sandbox-example",permalink:"/docs/use_cases/productionization/sandbox-example",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/productionization/sandbox-example.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Productionization",permalink:"/docs/category/productionization-1"}},c={},d=[];function l(e){const n={code:"code",h1:"h1",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"cluster-usage",children:"Cluster usage"}),"\n",(0,s.jsx)(n.p,{children:'SuperDuperDB allows developers, on the one hand to experiment and setup models quickly in scripts and notebooks, and on the other hand deploy persistent services, which are intended to "always" be on. These persistent services are:'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Dask scheduler"}),"\n",(0,s.jsx)(n.li,{children:"Dask workers"}),"\n",(0,s.jsx)(n.li,{children:"Vector-searcher service"}),"\n",(0,s.jsx)(n.li,{children:"Change-data-capture (CDC) service"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:o(88797).Z+"",width:"3297",height:"2400"})}),"\n",(0,s.jsxs)(n.p,{children:["To set up ",(0,s.jsx)(n.code,{children:"superduperdb"})," to use this cluster mode, it's necessary to add explicit configurations\nfor each of these components. The following configuration does that, as well as enabling a pre-configured\ncommunity edition MongoDB database:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"data_backend: mongodb://superduper:superduper@mongodb:27017/test_db\nartifact_store: filesystem://./data\ncluster:\n  cdc: http://cdc:8001\n  compute: dask+tcp://scheduler:8786\n  vector_search: http://vector-search:8000\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Add this configuration in ",(0,s.jsx)(n.code,{children:"/.superduperdb/config.yaml"}),", where ",(0,s.jsx)(n.code,{children:"/"})," is the root of your project."]}),"\n",(0,s.jsxs)(n.p,{children:["Once this configuration has been added, you're ready to use the ",(0,s.jsx)(n.code,{children:"superduperdb"})," sandbox environment, which uses\n",(0,s.jsx)(n.code,{children:"docker-compose"})," to deploy:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Standalone replica-set of MongoDB community edition"}),"\n",(0,s.jsx)(n.li,{children:"Dask scheduler"}),"\n",(0,s.jsx)(n.li,{children:"Dask workers"}),"\n",(0,s.jsx)(n.li,{children:"Vector-searcher service"}),"\n",(0,s.jsx)(n.li,{children:"Change-data-capture (CDC) service"}),"\n",(0,s.jsx)(n.li,{children:"Jupyter notebook service"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["To set up this environment, navigate to your local copy of the ",(0,s.jsx)(n.code,{children:"superduperdb"})," repository, and build the image with:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make testenv_image SUPERDUPERDB_EXTRAS=sandbox\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then start the environment with:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make testenv_init\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This last command starts containers for each of the above services with ",(0,s.jsx)(n.code,{children:"docker-compose"}),". You should see a bunch of logs for each service (mainly MongoDB)."]}),"\n",(0,s.jsx)(n.p,{children:"Once you have carried out these steps, you are ready to complete the rest of this notebook."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import os\n\n# move to the root of the project (assumes starts in `/examples`)\nos.chdir('../')\n\nfrom superduperdb import CFG\n\n# check that config has been properly set-up\nassert CFG.data_backend == 'mongodb://superduper:superduper@mongodb:27017/test_db'\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from superduperdb.backends.mongodb import Collection\nfrom superduperdb import superduper\n\ndb = superduper()\ndoc_collection = Collection('documents')\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/pymongo.json\n\nimport json\n\nwith open('pymongo.json') as f:\n    data = json.load(f)\n\ndata[0]\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from superduperdb import Document\n\nout, G = db.execute(\n    doc_collection.insert_many([Document(r) for r in data[:-100]])\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.metadata.show_jobs()\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import sentence_transformers\nfrom superduperdb import Model, vector\n\nmodel = Model(\n   identifier='all-MiniLM-L6-v2',\n   object=sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2'),\n   encoder=vector(shape=(384,)),\n   predict_method='encode',           # Specify the prediction method\n   postprocess=lambda x: x.tolist(),  # Define postprocessing function\n   batch_predict=True,                # Generate predictions for a set of observations all at once \n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from superduperdb import Listener, VectorIndex\n\njobs, vi = db.add(\n    VectorIndex(\n        identifier=f'pymongo-docs-{model.identifier}',\n        indexing_listener=Listener(\n            select=doc_collection.find(),\n            key='value',\n            model=model,\n            predict_kwargs={'max_chunk_size': 1000},\n        ),\n    )\n)\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"jobs[0].watch()\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.execute(doc_collection.find_one())\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from IPython.display import Markdown\n\nresult = sorted(db.execute(\n    doc_collection\n        .like(Document({'value': 'Aggregate'}), n=10, vector_index=f'pymongo-docs-{model.identifier}')\n        .find({}, {'_outputs': 0})\n), key=lambda r: -r['score'])\n\n# Display a horizontal line\ndisplay(Markdown('---'))\n\n# Iterate through the query results and display them\nfor r in result:\n    # Display the document's parent and res values in a formatted way\n    display(Markdown(f'### `{r[\"parent\"] + \".\" if r[\"parent\"] else \"\"}{r[\"res\"]}`'))\n    \n    # Display the value of the document\n    display(Markdown(r['value']))\n    \n    # Display a horizontal line\n    display(Markdown('---'))\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.drop(force=True)\n"})}),"\n",(0,s.jsx)(n.p,{children:"The great thing about this production mode, is that now allows data to be inserted into the service via other\nMongoDB clients, even from other programming languages and applications."}),"\n",(0,s.jsxs)(n.p,{children:["We show-case this here, by inserting the rest of the data using the official Python MongoDB driver ",(0,s.jsx)(n.code,{children:"pymongo"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"This cell will update the models, even if you restart the program:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import pymongo\n\ncoll = pymongo.MongoClient('mongodb://superduper:superduper@mongodb:27017/test_db').test_db.documents\n\ncoll.insert_many(data[-100:])\n"})}),"\n",(0,s.jsx)(n.p,{children:"To get an idea what is happening, you can view the logs of the CDC container on\nyour host by executing this command in a terminal:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker logs -n 20 testenv_cdc_1\n"})}),"\n",(0,s.jsx)(n.p,{children:"Note this won't work inside this notebook since it's running in its own container."}),"\n",(0,s.jsxs)(n.p,{children:["The CDC service should have captured the changes created with the ",(0,s.jsx)(n.code,{children:"pymongo"})," insert, and has submitted a new job(s)\nto the ",(0,s.jsx)(n.code,{children:"dask"})," cluster."]}),"\n",(0,s.jsx)(n.p,{children:"You can confirm that another job has been created and executed:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.metadata.show_jobs()\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You can view the ",(0,s.jsx)(n.code,{children:"stdout"})," of the most recent job with this command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.metadata.watch_job('a5077d81-0e00-4004-b501-23af356e0234')\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"db.execute(doc_collection.count_documents({'_outputs': {'$exists': 1}}))\n"})})]})}function h(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},88797:(e,n,o)=>{o.d(n,{Z:()=>s});const s=o.p+"assets/images/light-a62712fa65d77075618b2805c49a084a.png"},11151:(e,n,o)=>{o.d(n,{Z:()=>i,a:()=>a});var s=o(67294);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);