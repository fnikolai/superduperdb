"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2919],{73730:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>t,metadata:()=>a,toc:()=>d});var o=s(85893),r=s(11151);const t={},i="Creating a DB of image features in torchvision",a={id:"use_cases/items/resnet_features",title:"Creating a DB of image features in torchvision",description:"In this use-case, we demonstrate how to use a pre-trained network from torchvision to generate",source:"@site/content/use_cases/items/resnet_features.md",sourceDirName:"use_cases/items",slug:"/use_cases/items/resnet_features",permalink:"/docs/use_cases/items/resnet_features",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/items/resnet_features.md",tags:[],version:"current",frontMatter:{},sidebar:"useCasesSidebar",previous:{title:"Building Q&A Assistant Using Mongo and OpenAI",permalink:"/docs/use_cases/items/question_the_docs"},next:{title:"Sentiment analysis with transformers",permalink:"/docs/use_cases/items/sentiment_analysis_use_case"}},c={},d=[];function l(e){const n={a:"a",code:"code",h1:"h1",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.h1,{id:"creating-a-db-of-image-features-in-torchvision",children:["Creating a DB of image features in ",(0,o.jsx)(n.code,{children:"torchvision"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"!pip install superduperdb==0.0.12\n!pip install torchvision\n"})}),"\n",(0,o.jsxs)(n.p,{children:["In this use-case, we demonstrate how to use a pre-trained network from ",(0,o.jsx)(n.code,{children:"torchvision"})," to generate\nimage features for images which are automatically downloaded into MongoDB. We use a sample\nof the CoCo dataset (",(0,o.jsx)(n.a,{href:"https://cocodataset.org/#home",children:"https://cocodataset.org/#home"}),") to demonstrate the functionality."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"#curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/valsmall2014.zip\n!unzip -qq valsmall2014.zip\n"})}),"\n",(0,o.jsxs)(n.p,{children:["As usual, we instantiate the ",(0,o.jsx)(n.code,{children:"Datalayer"})," like this"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import os\nfrom superduperdb import superduper\nfrom superduperdb.backends.mongodb import Collection\n\n# Uncomment one of the following lines to use a bespoke MongoDB deployment\n# For testing the default connection is to mongomock\n\nmongodb_uri = os.getenv("MONGODB_URI","mongomock://test")\n# mongodb_uri = "mongodb://localhost:27017"\n# mongodb_uri = "mongodb://superduper:superduper@mongodb:27017/documents"\n# mongodb_uri = "mongodb://<user>:<pass>@<mongo_cluster>/<database>"\n# mongodb_uri = "mongodb+srv://<username>:<password>@<atlas_cluster>/<database>"\n\n# Super-Duper your Database!\nfrom superduperdb import superduper\ndb = superduper(mongodb_uri)\n\ncollection = Collection(\'coco\')\n'})}),"\n",(0,o.jsxs)(n.p,{children:["We then add all of the image URIs to MongoDB. The URIs can be a mixture of local file paths (",(0,o.jsx)(n.code,{children:"file://..."}),"), web URLs (",(0,o.jsx)(n.code,{children:"http..."}),") and\ns3 URIs (",(0,o.jsx)(n.code,{children:"s3://..."}),"). After adding the URIs, SuperDuperDB loads their content into MongoDB - no additional\noverhead or job definition required."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import glob\nimport random\n\nfrom superduperdb import Document as D\nfrom superduperdb.ext.pillow import pil_image as i\n\nuris = [f'file://{x}' for x in glob.glob('valsmall2014/*.jpg')]\n\ndb.execute(collection.insert_many([D({'img': i(uri=uri)}) for uri in uris], encoders=(i,)))\n"})}),"\n",(0,o.jsxs)(n.p,{children:["We can verify that the images were correctly stored in the ",(0,o.jsx)(n.code,{children:"Datalayer"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from IPython.display import display\n\n# Jupyter often crashes with bigger images\ndisplay_image = lambda x: display(x.resize((round(x.size[0] * 0.5), round(x.size[1] * 0.5))))\n\nx = db.execute(collection.find_one())['img'].x\n\ndisplay_image(x)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Now let's create the ",(0,o.jsx)(n.code,{children:"torch"}),"+",(0,o.jsx)(n.code,{children:"torchvision"})," model using the ",(0,o.jsx)(n.code,{children:"TorchModel"})," wrapper from SuperDuperDB.\nIt's possible to create arbitrary pre- and post-processing along with the model forward pass:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nimport warnings\n\nfrom superduperdb.ext.torch import TorchModel, tensor\n\nt = transforms.Compose([\n    transforms.Resize((224, 224)),   #must same as here\n    transforms.CenterCrop((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ndef preprocess(x):\n    try:\n        return t(x)\n    except Exception as e:\n        warnings.warn(str(e))\n        return torch.zeros(3, 224, 224)\n\nresnet50 = models.resnet50(pretrained=True)\nmodules = list(resnet50.children())[:-1]\nresnet50 = nn.Sequential(*modules)\n\nmodel = TorchModel(\n    identifier='resnet50',\n    preprocess=preprocess,\n    object=resnet50,\n    postprocess=lambda x: x[:, 0, 0],\n    encoder=tensor(torch.float, shape=(2048,))\n)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Let's verify ",(0,o.jsx)(n.code,{children:"model"})," by testing on a single data-point ",(0,o.jsx)(n.code,{children:"one=True"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"model.predict(x, one=True)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Now that we've got the model ready, we can apply it to the images in the ",(0,o.jsx)(n.code,{children:"Datalayer"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"model.predict(\n    X='img',\n    db=db,\n    select=collection.find(),\n    batch_size=10,\n    max_chunk_size=3000,\n    in_memory=False,\n    listen=True,\n)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Let's verify that the features were stored in the ",(0,o.jsx)(n.code,{children:"Datalayer"}),". You can see them in the\n",(0,o.jsx)(n.code,{children:"_outputs.img.resnet50"})," field:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"db.execute(collection.find_one()).unpack()\n"})})]})}function p(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>a,a:()=>i});var o=s(67294);const r={},t=o.createContext(r);function i(e){const n=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);