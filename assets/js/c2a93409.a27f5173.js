"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[4957],{81217:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>p,frontMatter:()=>d,metadata:()=>r,toc:()=>c});var a=s(85893),t=s(11151);const d={sidebar_position:2},i="SQL Vector Search",r={id:"use_cases/sql-example",title:"SQL Vector Search",description:"End-2-end example using SQL databases",source:"@site/content/use_cases/sql-example.md",sourceDirName:"use_cases",slug:"/use_cases/sql-example",permalink:"/docs/use_cases/sql-example",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/sql-example.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Chunked",permalink:"/docs/use_cases/vector_search/chunked_vector_search"},next:{title:"Chatbot",permalink:"/docs/category/chatbot-1"}},o={},c=[{value:"End-2-end example using SQL databases",id:"end-2-end-example-using-sql-databases",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Connect to datastore",id:"connect-to-datastore",level:2},{value:"Load dataset",id:"load-dataset",level:2},{value:"Define schema",id:"define-schema",level:2},{value:"Add data to the datastore",id:"add-data-to-the-datastore",level:2},{value:"Build SuperDuperDB <code>Model</code> instances",id:"build-superduperdb-model-instances",level:2},{value:"Create a Vector-Search Index",id:"create-a-vector-search-index",level:2},{value:"Search Images Using Text",id:"search-images-using-text",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"sql-vector-search",children:"SQL Vector Search"}),"\n",(0,a.jsx)(n.h2,{id:"end-2-end-example-using-sql-databases",children:"End-2-end example using SQL databases"}),"\n",(0,a.jsx)(n.p,{children:"SuperDuperDB allows users to connect to a MongoDB database, or any one of a range of SQL databases, i.e. from this selection:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"MongoDB"}),"\n",(0,a.jsx)(n.li,{children:"PostgreSQL"}),"\n",(0,a.jsx)(n.li,{children:"SQLite"}),"\n",(0,a.jsx)(n.li,{children:"DuckDB"}),"\n",(0,a.jsx)(n.li,{children:"BigQuery"}),"\n",(0,a.jsx)(n.li,{children:"ClickHouse"}),"\n",(0,a.jsx)(n.li,{children:"DataFusion"}),"\n",(0,a.jsx)(n.li,{children:"Druid"}),"\n",(0,a.jsx)(n.li,{children:"Impala"}),"\n",(0,a.jsx)(n.li,{children:"MSSQL"}),"\n",(0,a.jsx)(n.li,{children:"MySQL"}),"\n",(0,a.jsx)(n.li,{children:"Oracle"}),"\n",(0,a.jsx)(n.li,{children:"pandas"}),"\n",(0,a.jsx)(n.li,{children:"Polars"}),"\n",(0,a.jsx)(n.li,{children:"PySpark"}),"\n",(0,a.jsx)(n.li,{children:"Snowflake"}),"\n",(0,a.jsx)(n.li,{children:"Trino"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["In this example we show case how to implement multimodal vector-search with DuckDB.\nThis is a simple extension of multimodal vector-search with MongoDB, which is\njust slightly easier to set-up (see ",(0,a.jsx)(n.a,{href:"https://docs.superduperdb.com/docs/use_cases/items/multimodal_image_search_clip",children:"here"}),").\nEverything we do here applies equally to any of the above supported SQL databases, as well as to tabular data formats on disk, such as ",(0,a.jsx)(n.code,{children:"pandas"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.p,{children:"Before working on this use-case, make sure that you've installed the software requirements:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install superduperdb[demo]\n"})}),"\n",(0,a.jsx)(n.h2,{id:"connect-to-datastore",children:"Connect to datastore"}),"\n",(0,a.jsxs)(n.p,{children:["The first step in any ",(0,a.jsx)(n.code,{children:"superduperdb"})," workflow is to connect to your datastore.\nIn order to connect to a different datastore, add a different ",(0,a.jsx)(n.code,{children:"URI"}),", e.g. ",(0,a.jsx)(n.code,{children:"postgres://..."}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import os\nfrom superduperdb import superduper\n\nos.makedirs('.superduperdb', exist_ok=True)\ndb = superduper('duckdb://.superduperdb/test.ddb')\n"})}),"\n",(0,a.jsx)(n.h2,{id:"load-dataset",children:"Load dataset"}),"\n",(0,a.jsx)(n.p,{children:"Now, Once connected, add some data to the datastore:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/coco_sample.zip\n!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/captions_tiny.json\n!unzip coco_sample.zip\n!mkdir -p data/coco\n!mv images_small data/coco/images\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import json\nimport pandas\nimport PIL.Image\n\nwith open(captions_tiny.json') as f:\n    data = json.load(f)[:500]\n    \ndata = pandas.DataFrame([\n    {\n        'image': r['image']['_content']['path'], \n         'captions': r['captions']\n    } for r in data   \n])\ndata['id'] = pandas.Series(data.index).apply(str)\nimages_df = data[['id', 'image']]\n\nimages_df['image'] = images_df['image'].apply(PIL.Image.open)\ncaptions_df = data[['id', 'captions']].explode('captions')\n"})}),"\n",(0,a.jsx)(n.h2,{id:"define-schema",children:"Define schema"}),"\n",(0,a.jsxs)(n.p,{children:["This use-case requires a table with images, and a table with text.\nSuperDuperDB extends standard SQL functionality, by allowing developers to define\ntheir own data-types via the ",(0,a.jsx)(n.code,{children:"Encoder"})," abstraction."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.backends.ibis.query import Table\nfrom superduperdb.backends.ibis.field_types import dtype\nfrom superduperdb.ext.pillow import pil_image\nfrom superduperdb import Schema\n\ncaptions = Table(\n    'captions', \n    primary_id='id',\n    schema=Schema(\n        'captions-schema',\n        fields={'id': dtype(str), 'captions': dtype(str)},\n    )\n)\n\nimages = Table(\n    'images', \n    primary_id='id',\n    schema=Schema(\n        'images-schema',\n        fields={'id': dtype(str), 'image': pil_image},\n    )\n)\n\ndb.add(captions)\ndb.add(images)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"add-data-to-the-datastore",children:"Add data to the datastore"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"_ = db.execute(images.insert(images_df))\n_ = db.execute(captions.insert(captions_df))\n"})}),"\n",(0,a.jsxs)(n.h2,{id:"build-superduperdb-model-instances",children:["Build SuperDuperDB ",(0,a.jsx)(n.code,{children:"Model"})," instances"]}),"\n",(0,a.jsxs)(n.p,{children:["This use-case uses the ",(0,a.jsx)(n.code,{children:"superduperdb.ext.torch"})," extension.\nBoth models used, output ",(0,a.jsx)(n.code,{children:"torch"})," tensors, which are encoded with ",(0,a.jsx)(n.code,{children:"tensor"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import clip\nimport torch\nfrom superduperdb.ext.torch import TorchModel, tensor\n\n# Load the CLIP model\nmodel, preprocess = clip.load(\"RN50\", device='cpu')\n\n# Define a tensor type\nt = tensor(torch.float, shape=(1024,))\n\n# Create a TorchModel for text encoding\ntext_model = TorchModel(\n    identifier='clip_text',\n    object=model,\n    preprocess=lambda x: clip.tokenize(x)[0],\n    encoder=t,\n    forward_method='encode_text',    \n)\n\n# Create a TorchModel for visual encoding\nvisual_model = TorchModel(\n    identifier='clip_image',\n    object=model.visual,    \n    preprocess=preprocess,\n    encoder=t,\n)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"create-a-vector-search-index",children:"Create a Vector-Search Index"}),"\n",(0,a.jsxs)(n.p,{children:["Let's define a mult-modal search index on the basis of the models imported above.\nThe ",(0,a.jsx)(n.code,{children:"visual_model"})," is applied to the images, to make the ",(0,a.jsx)(n.code,{children:"images"})," table searchable."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import VectorIndex, Listener\n\ndb.add(\n    VectorIndex(\n        'my-index',\n        indexing_listener=Listener(\n            model=visual_model,\n            key='image',\n            select=images,\n        ),\n        compatible_listener=Listener(\n            model=text_model,\n            key='captions',\n            active=False,\n            select=None,\n        )\n    )\n)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"search-images-using-text",children:"Search Images Using Text"}),"\n",(0,a.jsx)(n.p,{children:"Now we can demonstrate searching for images using text queries:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import Document\n\nres = db.execute(\n    images\n        .like(Document({'captions': 'dog catches frisbee'}), vector_index='my-index', n=10)\n        .limit(10)\n)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"res[3]['image'].x\n"})})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>r,a:()=>i});var a=s(67294);const t={},d=a.createContext(t);function i(e){const n=a.useContext(d);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(d.Provider,{value:n},e.children)}}}]);